{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import loadfiles\n",
    "p,n  = loadfiles.loaddata(\"/home/pig/data\",numneg=1500, pos='both')\n",
    "#X1,X2,Y1,Y2 = train_test_split(test_size=.33, random_state=1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "allfeatures = list(p[1].keys())[:-1] # the filenames are the last one and we dont need that \n",
    "pprint.pprint(list(p[1].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clean(di,oklist):\n",
    "    for k in list(di.keys()):\n",
    "        if k not in oklist:\n",
    "            di.pop(k)\n",
    "    return di\n",
    "\n",
    "df = pd.DataFrame(p+n)\n",
    "X= df.to_numpy()\n",
    "y= [1]*len(p)+[0]*len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if is nan\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV as rec\n",
    "X = StandardScaler().fit_transform(X)\n",
    "algo=[\n",
    "    RandomForestClassifier( n_estimators=30, class_weight='balanced'),\n",
    "    SVC(kernel=\"linear\",class_weight='balanced', C=0.025)\n",
    "]\n",
    "    #SVC(gamma=2, C=1,class_weight='balanced'),\n",
    "for e in algo:\n",
    "    sel=  rec(e,n_jobs = -1 )\n",
    "    sel = sel.fit(X, y)\n",
    "    pprint.pprint([b for a,b in zip(sel.support_, df.columns) if a])\n",
    "    \n",
    "    FEATURELIST = [b for a,b in zip(sel.support_, df.columns) if a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean(di,oklist):\n",
    "    for k in list(di.keys()):\n",
    "        if k not in oklist:\n",
    "            di.pop(k)\n",
    "    return di\n",
    "\n",
    "asd = [ clean(e,FEATURELIST) for e in p+n ]\n",
    "df = pd.DataFrame(asd)\n",
    "X= df.to_numpy()\n",
    "y= [1]*len(p)+[0]*len(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train some classifiers to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "names = [\"Nearest Neighbors\",\"Linear SVM\", \"RBF SVM\",\n",
    "         #\"Gaussian Process\", # 2 slow\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel=\"linear\",class_weight='balanced', C=0.025),\n",
    "    SVC(gamma=2, C=1,class_weight='balanced'),\n",
    "    #SVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5,class_weight='balanced'),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=25, max_features=10, class_weight='balanced'), # this was at 75% with all the features i have of now 20-09\n",
    "    #RandomForestClassifier(max_depth=5, n_estimators=25, max_features=5,class_weight='balanced'),\n",
    "    MLPClassifier(alpha=.001, max_iter=2000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "    ]\n",
    "\n",
    "#X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "import draw\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print (name,score)\n",
    "    \n",
    "    #print (clf.predict(X_test))\n",
    "    draw.matrix(y_test,clf.predict(X_test), np.array(['bad','good']),normalize=False,title =name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at a decission tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "estimator = classifiers[3]\n",
    "\n",
    "\n",
    "graph = Source(tree.export_graphviz(estimator, out_file=None\n",
    "   , feature_names=df.columns, class_names=['0', '1'] \n",
    "   , filled = True))\n",
    "display(SVG(graph.pipe(format='svg')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature interdependance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set(style=\"ticks\")\n",
    "#nuX = StandardScaler().fit_transform(X)\n",
    "nuX =X\n",
    "names=oklist\n",
    "\n",
    "df = pd.DataFrame(nuX,columns = names)\n",
    "df.insert(len(oklist),'class',[str(x)+\" class\" for x in y ])\n",
    "if len(df.columns)<13:\n",
    "    sns.pairplot(df, hue=\"class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance  according to the random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    forest = classifiers[4]\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f) %s\" % (f + 1, indices[f], importances[indices[f]], df.columns[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
